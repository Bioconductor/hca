---
title: "December 31 Comments"
author: "Martin Morgan"
date: "12/31/2020"
output: html_document
---

# Setup

I'll load packages we need

```{r, message = FALSE}
library(jsonlite)
library(httr)
library(dplyr)
```

I'm just making some 'mock' data, because my interent connection is so
poor...

```{r}
lst <- list(
    hits = list(
        list(projects = list(list(projectTitle = "First project"))),
        list(projects = list(list(projectTitle = "Second project")))
    )
)
```

# General

This looks really great, Maya! Here are some general / trivial
comments, and then in the next sections I outline what I might have
done differently. It actually took me a long time to work through
this, so don't be discouraged if it is overwhelming!

- Don't commit `.Rhistory` to git, because it could contain more-or-less
  private information. Add a single line

    ```
    .Rhistory
    ```

  to the file `HCAccess/.gitignore`, and `git rm .Rhistory` to remove
  the file from the head of the branch. If paranoid, look into
  removing the file from the repository itself.

- Please wrap text and code to 80 characters; it seems arbitrary but
  it's often convvenient to just use a terminal and `less` to scan
  through files quickly, and the 80 character wrap fits into a
  standard console window. There's a GUI option under Tools -> Global
  Options -> Code -> Display` to 'Show margin' at column 80. I think
  there should be a magic command to 'hard wrap' long lines to 80
  characters, but I'm not seeing it... Also, I see that I'm a
  hypocrite here, with long lines in my own Rmd document!

  Also under ... Code -> Saving click the options to strip trailing
  horizontal white space and to ensure that source files end with new
  lines.

- Use `##` for comments that are meant to be aligned with the left
  edge of the code; `#` for 'trailing' comments

    ```{r, eval = FALSE}
    ## here's a comment
    if (condition) {
        ## and here...
        x = 1           # and here
    }
    ```

# Using `sapply()` to generate a vector of project titles

I asked

- Use `sapply()` with `X = lst$hits` to generate a vector of project
  titles matching our query.

but hadn't really given it enough thought, I had in mind a solution

```{r}
sapply(lst$hits, function(hit) {
    hit$projects[[1]][["projectTitle"]]
})
```

but your answer

```{r}
# function for extracting project titles
extract_proj_titles <- function(X = list()){
    # print(identical(X, lst[["hits"]]))
    proj_titles <- c()
    num_hits <- length(X)
    # print(paste('num_hits:', num_hits))
    for (hit_ind in 1:num_hits){
        current_hit <- X[[hit_ind]]
        num_projs <- length(current_hit$projects)
        for (proj_ind in 1:num_projs){
            current_proj <- current_hit$projects[[proj_ind]]
            proj_titles <- append(proj_titles, current_proj$projectTitle)
        }
    }

    return(proj_titles)
}

sapply(X = list(lst$"hits"), FUN = extract_proj_titles)
```

points out that the data structure implies multiple projects per
hit. After the long commentary below, I ended up with the following

```{r}
## Use '.' to prefix 'helper' functions not meant for the 'end user'.
##
## For each hit, iterate over all projects and extract 'element' from each.
.projects_elt <-
    function(hit, element)
{
    ## 'vapply': like 'sapply', but return type of FUN is specified (3rd arg)
    ## `[[`: x[["foo"]] is actually a function call `[[`(x, "foo")
    vapply(hit$projects, `[[`, character(1), element)
}

project_titles <-
    function(lst)
{
    lapply(lst$hits, .projects_elt, "projectTitle")
}

project_titles(lst)
```

Here's how I got from your answer to mine...

## Avoid 'copy-and-append'

At Maya-Dec-29.Rmd:119 you create a variable, and then fill it in a
`for` loop, like

```{r, eval = FALSE}
proj_titles <- c()
for (i in 1:num_hits) {
    ## ...
    proj_titles <- append(proj_titles, current_proj$projectTitle)
}
```

This makes a copy of the current `proj_titles` each time through the
loop, so copies 1, 2, ..., n items the first, second, ..., nth time
through the loop. The total number of elements copied is 1 + 2 + ... +
n, which turns out to be `n (n - 1) / 2` -- the number of copies
scales with, approximately, the square of n, so becomes very slow as
`n` becomes large; check it out!

 ```{r, cache = TRUE}
n <- 1000; x <- 0; system.time(for (i in 1:n) x <- append(x, i))  #  0.012 seconds
n <- 10000; x <- 0; system.time(for (i in 1:n) x <- append(x, i)) #  0.65 s
n <- 100000; x <- 0; system.time(for (i in 1:n) x <- append(x, i))# 73.6 s
```

Each line increase the problem size by an order of magnitude, but the
execution time increases by much more than that!

A much better strategy is 'pre-allocate and fill'

```{r}
n <- 100000; x1 <- integer(n)
system.time({
    for (i in 1:n)
        x1[i] <- i
}) # 0.013 s
```

## Use iteration on list elements directly, without an index

Your code has

```{r, eval = FALSE}
for (hit_ind in 1:num_hits) {
    current_hit <- X[[hit_ind]]
    ...
}
```

but actually the elements of the list can be indexed directly

```{r}
my_list <- list(1, "foo", pi)
for (elt in my_list)
    print(elt)
```

so the code could have been written

```{r, eval = FALSE}
for (current_hit in X) {
    ## ...
}
```

and a little more broadly

```{r}
extract_proj_titles <- function(X = list()){
    proj_titles <- c()
    for (current_hit in X) {
        for (current_proj in current_hits$projects) {
            proj_titles <- append(proj_titles, current_proj$projectTitle)
        }
    }

    return(proj_titles)
}
```

## Use `lapply()` and `sapply()` (or `vapply()`) instead of `for` loops

### From `for` to `sapply()`

For a `for` loop like

```{r}
for (i in 1:10)
    sqrt(i)
```

one can think of a vector `X = 1:10` over which the iteration is
occuring, and function `FUN = function(i) sqrt(i)` applied to each
element of the iteration

```{r}
X <- 1:10
FUN <- function(i) sqrt(i)
for (i in X)
    FUN(i)
```

One could instead use `sapply`, to apply `FUN` to each element of `X`

```{r}
sapply(X, FUN)
```

One immediate advantage of this is that the result is returned as a
vector, without the developer having to allocate and manage memory

```{r}
result <- sapply(X, FUN)
result
```

Our 'pre-allocate and fill' example could be written as

```{r}
n <- 100000
X <- 1:n
FUN <- function(i) i
x2 <- sapply(X, FUN)
```

This is slower than a `for` loop, but still plenty fast and scaling
linearly with `n`.

```{r}
system.time(x2 <- sapply(X, FUN)) # 0.13 s
identical(x1, x2)                 # same answer
```

It could be written a little less pedantically as

```{r}
n <- 100000
x3 <- sapply(1:n, function(i) i)
```

### `sapply()` versus `lapply()`

The `s` in `sapply()` stands for 'simplify' -- it produces a list of
results, and tries to simplify the list to a vector. This is not
always appropriate

```{r}
X <- list(1, "foo")
sapply(X, function(i) i) # _numeric_ value 1 coerced to _character_ value "1"
```

and one might wish intead to create a list to maintain heterogenous
types. Use `lapply()` for this.

```{r}
## lapply() returns a list. Here the first element is a numeric '1'
## and the second element is a character vector.
result <- lapply(X, function(i) i)
```

If one actually wants to force the simplification, use `unlist()`

```{r}
unlist(result)
```

In the following examples where the elements of the list are the same
length, simplification is possible

```{r}
my_list <- list(1, 2, 3, 4, 5, 6)
sapply(my_list, function(i) sqrt(i)) # numeric vector
my_list <- list(1:3, 4:6)
sapply(my_list, function(i) sqrt(i)) # numeric *matrix*
```

but here the elements are of different lengths, and `sapply()` is
unsure what data represention is appropriate and so returns a list

```{r}
my_list <- list(1:2, 4:6)
sapply(my_list, function(i) sqrt(i))
```

### `sapply()` versus `vapply()`

There is one case where `sapply()` can produce perhaps unexpected
results. `sqrt()` returns a numeric vector, and for appropriate input
`sapply()` does too

```{r}
X <- 1:3
sapply(X, function(i) sqrt(i))
```

But what about the edge case where `X` is a *zero-length* integer
vector? `sqrt()` always returns a numeric vector

```{r}
X <- integer(0)
X
sqrt(X)
```

so shouldn't `sapply()` also return a zero-length numeric vector, to
match the length of the argument `X` and the return value of `sqrt()`?

```{r}
sapply(X, function(i) sqrt(i))
```

Nope! Since `X` is length 0, `function(i) sqrt(i)` is never called,
and `sapply()` has no idea what its return value is -- the best it can
do is return a zero-length list. This 'edge case' causes lots of
problems in package code, because inevitably the user's input touches
on this case, and the developer (mistakenly) tries to handle the
situation with something like

```{r, eval = FALSE}
result <- sapply(X, FUN)
if (is.list(result) && length(result == 0))
    ## should have been a zero-length numeric vector, stupid R!
    result <- numeric(0)
```

This complicates the code, because you have to think through both
(implicit) branches of the `if` statement, doubling the amount of
thinking you need to do. Instead, if `FUN` always returns a particular
value, e.g., a numeric vector of length 1, use `vapply()` with the
third, required, argument being a prototype (in this case, a length 1
numeric vector) for the type of the result.

```{r}
result <- vapply(integer(0), function(i) sqrt(i), numeric(1))
```

`result` is then always a numeric vector, and it is not necessary to
handle the special case of a zero-length `X`.

### Useful patterns with the `*apply()` family


There are further patterns that can be useful with the `apply()`
family of functions. Consider the `log()` function, which can take two
arguments -- the vector of values to calculate the log of, and the
base to use.

```{r}
X <- list(1:2, 3:5)
FUN <- function(i)
    log(i, base = 2)
lapply(X, FUN)
```

This could be re-written so that the `FUN` argument to `lapply()`
takes two arguments, with the second (invariant) argument provided as
part of `lapply()`, rather than encoded in the function. This allows
`FUN` to be used in a broader range of circumstances.

```{r}
FUN <- function(i, base)
    log(i, base = base)
lapply(X, FUN, base = 2)
lapply(X, FUN, base = 10)
```

As another pattern, note that `FUN()` just passes arguments to
`log()`, so one might as well use `log()` directly

```{r}
lapply(X, log, base = 2)
```

## Your code

### Inner loop

The loop

```{r, eval = FALSE}
for (current_proj in current_hits$projects) {
    proj_titles <- append(proj_titles, current_proj$projectTitle)
}
```

can be written as

```{r, eval = FALSE}
projects <- current_hits$projects
proj_titles <- sapply(projects, function(project) project$projectTitle)
```

or

```{r, eval = FALSE}
proj_titles <- sapply(projects, function(project) project[["projectTitle"]])
```

or, if we aren't interested in simplifying the result

```{r, eval = FALSE}
proj_titles <- lapply(projects, function(project) project[["projectTitle"]])
```

Using the first useful pattern mentiond above, we could revise the
function in this expression as

```{r, eval = FALSE}
FUN <- function(project, element)
    project[[element]]
proj_titles <- lapply(projects, FUN, "projectTitle")
```

This would allow us, for instance, to extract elements other than
`"projectTitle"` from `projects`.

And just a little bit more (maybe too) clever... `[[` as used above
can actually be invoked as a function with two arguments. The first
argument is the variable on the left-hand side of `[[`, and the second
argument is the name of the element to extract.

```{r}
project <- list(projectTitle = "foo")
project[["projectTitle"]]
`[[`(project, "projectTitle")
```

So we see that `FUN` just passes its two arguments to `[[`, and we can
remove the middle man

```{r}
projects <- lst$hits[[1]]$projects
proj_titles <- lapply(projects, `[[`, "projectTitle")
```

Since `"projectTitle"` is always character vector of length 1, a more
robust solution uses `vapply()` as

```{r}
vapply(projects, `[[`, character(1), "projectTitle")
```

### Outer loop

Returning to the basic data structure

```{r}
lst$hits[[1]]$projects[[1]]$projectTitle
```

When I asked

- Use `sapply()` with `X = lst$hits` to generate a vector of project
  titles matching our query.

I guess I was implicitly thinking that each hit corresponded to a
single project, and each project had exactly one title, so naively

```{r}
FUN <- function(hit)
    hit$projects[[1]]$projectTitle
sapply(lst$hits, FUN)
```

or more robustly

```{r}
vapply(lst$hits, FUN, character(1))
```

But your (updated) function

```{r, eval = FALSE}
extract_proj_titles <- function(X = list()){
    proj_titles <- c()
    for (current_hit in X) {
        for (current_proj in current_hits$projects) {
            proj_titles <- append(proj_titles, current_proj$projectTitle)
        }
    }

    return(proj_titles)
}
```

probably captures the implied richness of possible results. Each hit
can apparently have several projects, so

```{r}
FUN <- function(hit)
    vapply(hit$projects, `[[`, character(1), "projectTitle")
```

and there is no reason to think that each hit has the same number of
projects (so the outer `sapply()` is not appropriate)

```{r}
lapply(lst$hits, FUN)
```

Actually, it is useful to generalize `FUN` as `.projects_elt`. I'm
using the `.` to indicate that the function is not usually called by
the 'end user'.

```{r}
.projects_elt <-
    function(hit, element)
{
    vapply(hit$projects, `[[`, character(1), element)
}

## or maybe...
project_titles <-
    function(lst)
{
    lapply(lst$hits, .projects_elt, "projectTitle")
}
```

# Formulate additional filters

Your work looks correct. Good job!

I might refactor things so that 'create filters' is different from
'create parameters' and 'construct full URL', because the information
and sorts of operations needed to create filters and parameters is
different from that to construct the full URL. Also I think each step
migth become more complicated, and it'll be easier to update more
modular code.

## Create projects filters from user input

I added 'roxygen2' tags in anticipation of inclusion in a package,
even though they have no effect in a script.

```{r}
#' @importFrom jsonlite toJSON
#'
#' @importFrom utils URLencode
create_filter <-
    function(filter = list())
{
    ## validate inputs
    stopifnot(
        is.list(filter),        # must be a list
        !is.null(names(filter)) # elements must have names(?)
    )

    json <- toJSON(filter)
    URLencode(json, reserved = TRUE)
}
```

To iterate on this just a bit, it seems like we would like to support
empty filters `create_filter()`, but actually our validation criteria
are too strict

```{r, error = TRUE}
create_filter()
```

Also, I notice that `toJSON()` creates a JSON array when a list is
unnamed, but a hash when it is...

```{r}
filter <- list()
toJSON(filter)

names(filter) <- character()
toJSON(filter)
```

I update the function signature so that it is correct by default,
using `setNames()` to add names to the empty list.

```{r}
#' @importFrom jsonlite toJSON
#'
#' @importFrom utils URLencode
create_filter <-
    function(filter = setNames(list(), character()))
{
    ## validate inputs
    stopifnot(
        is.list(filter),        # must be a list
        !is.null(names(filter)) # elements must have names(?)
    )

    json <- toJSON(filter)
    URLencode(json, reserved = TRUE)
}

create_filter()
```

It might be more user-friendly to allow the user to provide an unnamed
list, and in that case do the work of adding names for them; more work
/ complexity for us, but 'easier' for them. Or maybe it's not eaiser
for them, because now they have to remember a more complicated rule
'always provided a named list, expect if it empty'...

```{r}
## support unnamed empty lists from the user...
projects_filter <-
    function(filter = setNames(list(), character()))
{
    ## validate inputs
    stopifnot(
        ## 'filter' must be a list
        is.list(filter),
        ## length 0 or elements must have names
        length(filter) == 0L || !is.null(names(filter))
    )

    ## make sure zero-length filters have names
    if (length(filter) == 0L) {
        names(filter) <- character()
    }

    json <- toJSON(filter)
    URLencode(json, reserved = TRUE)
}

projects_filter(list())
```

Is this filter legal / encoded correctly?

```{r}
filter <- list(
    organ = list(is = "pancreas"),
    genusSpecies = list(is = "Homo sapiens")
)
encoded <- projects_filter(filter)
encoded
URLdecode(encoded)
```

## Default 'projects' parameters

It seems like there are different ways for accessing data (projects,
files, ...) and likely the parameters that determine how each type of
result is determined will differ. So I'll create a helper function to
create appropriate defaults. It's usually easier on the user, and
easier to document and validate, explicit function arguments than to
accept something generic like a `list()`.

```{r}
projects_parameters <-
    function(
        filter = projects_filter(),
        catalog = "dcp2",
        size = 100,
        sort = "projectTitle",
        order = c("asc", "desc")
    )
{
    ## match.arg() validates that 'order' provided by the user is one
    ## of the vector of default values in the function argument; if
    ## 'order' is not specified by the user, then the first ('asc') is
    ## used. 'order' can be considered to have been validated after
    ## this step.
    order <- match.arg(order)

    ## '100' is a numeric value, but we want integer...
    size <- as.integer(size)
    stopifnot(
        length(filter) == 1L, is.character(filter), # FIXME: better validation
        length(catalog) == 1L, is.character(catalog),
        length(size) == 1L, is.integer(size),
        length(sort) == 1L, is.character(sort)
    )


    parameters <- list(
        catalog = catalog,
        filter = filter,
        size = size,
        sort = sort,
        order = order
    )

    paste(names(parameters), unname(parameters), sep = "=", collapse = "&")
}
```

`projects_parameters()` builds on `projects_filter()`, and the
no-argument invocation as well aas our simple test case produces valid
output.

```{r}
projects_parameters()

filter <- list(
    organ = list(
        is = "pancreas"
    )
)
projects_parameters(projects_filter(filter))
```

## Complete URl

Not too complicated here. I ordered the parameters from 'most likely
to be of interest to the user' to 'most constant / least interesting
to the user'. I used our `projects_parameters()` for providing the
parameters.

```{r}
projects_url <-
    function(
        parameters = projects_parameters(),
        endpoint = "/index/projects",
        base_url = "https://service.dev.singlecell.gi.ucsc.edu"
    )
{
    ## validate arguments
    stopifnot(
        ## FIXME: better validation
        length(parameters) == 1L, is.character(parameters),
        length(endpoint) == 1L, is.character(endpoint),
        length(base_url) == 1L, is.character(base_url),
        startsWith(base_url, "https://")
    )

    paste0(base_url, endpoint, "?", parameters)
}

projects_url()
```

## API request

Again, your code looks good! I had the `tryCatch()` in my code so that
it could fail as an example, but really if the request fails then the
user needs to know about it and we can't continue. I didn't use
`str()`, which is mostly for visualizing the structure of a
result. And I didn't use an explicit `return()`, just letting the
function return the last expression it evaluates.

```{r}
#' @importFrom httr GET stop_for_status headers content
hca_call <-
    function(url = projects_url())
{
    stopifnot(
        length(url) == 1L, is.character(url), startsWith(url, "https://")
    )

    response <- GET(url)
    stop_for_status(response)
    list(
        headers = heders(response),
        content = content(response)
    )
}    
```

## All together

Your code looks good here, too! I have

```{r}
filter1 <- list(organ = list(is = "pancreas"))
url1 <-
    filter1 %>%
    projects_filter() %>%
    projects_parameters() %>%
    projects_url()

filter2 <- list(genusSpecies = list(is = "Homo sapiens"))
url2 <-
    filter2 %>%
    projects_filter() %>%
    projects_parameters() %>%
    projects_url()

filter3 <- list(
    organ = list(is = "pancreas"),
    genusSpecies = list(is = "Homo sapiens")
)
url3 <-
    filter3 %>%
    projects_filter() %>%
    projects_parameters() %>%
    projects_url()
```

Each of these should I guess return valid responses

```{r, eval = FALSE}
result <- hca_call(url1)
project_titles(result$content)
```

The repetition enourages me to revisit the design, wanting something like

```{r, eval = FALSE}
index_projects(filter)
```

to 'just work'

# From list-of-lists to tibble

Again, your solution looks great; I did it the following way, thinking
of the process of 'querying' the list-of-lists for particular
components (e.g., all "projectTitle") and then assembling the
components into a tibble. I repeatedly visit each 'leaf' node to
extract a single piece of information. This is kind of the inverse of
what you do, which is to visit each leaf node once, extracting
multiple pieces of information.

## Setup

```{r}
library(tidyr) # tidyr::unnest()
```

Some mock data

```{r}
content <- list(
    hits = list(
        list(
            projects = list(
                list(
                    projectTitle = "First project",
                    genusSpecies = "Homo sapiens"
                ),
                list(
                    projectTitle = "Second project",
                    genusSpecies = "Mus musculus"
                )
            )
        ),
        list(
            projects = list(
                list(
                    projectTitle = "Third project",
                    genusSpecies = "Homo sapiens"
                )
            )
        )
    )
)
```

Modified from ealier

```{r}
## extract a single element from a hit; returns a vector
.projects_elt <-
    function(hit, element)
{
    vapply(hit$projects, `[[`, character(1), element)
}

## extract a single element from all hits; returns a list-of-vectors
.content_elt <-
    function(content, element)
{
    lapply(content$hits, .projects_elt, element)
}
```

First approach: create a tibble by extracting each element.

```{r}
tbl <- tibble(
    projectTitle = .content_elt(content, "projectTitle"),
    genusSpecies = .content_elt(content, "genusSpecies")
)
```

`tbl` contains nested columns; unnest them with `tidyr::unnest()`

```{r}
tbl %>%
    unnest(c("projectTitle", "genusSpecies"))
```

As a function:

```{r}
#' @importFrom tidyr unnest
.content_tibble <-
    function(content)
{
    tbl <- tibble(
        projectTitle = .content_elt(content, "projectTitle"),
        genusSpecies = .content_elt(content, "genusSpecies")
    )
    tbl %>%
        unnest(c("projectTitle", "genusSpecies"))
}

.content_tibble(content)
```

Add (`mutate()`) columns that reflect the 'geometry' of the results --
the hit index as an integer vector, and the project index within each
hit, as a list of integer vectors. Unnest the list columns

```{r}
#' @importFrom tidyr unnest
.content_tibble <-
    function(content)
{
    tbl <-
        ## create tibble
        tibble(
            projectTitle = .content_elt(content, "projectTitle"),
            genusSpecies = .content_elt(content, "genusSpecies")
        ) %>%
        ## add hit and project index
        mutate(
            hit_index = seq_along(projectTitle),
            project_index = lapply(lengths(projectTitle), seq_len)
        ) %>%
        ## unnest list columns
        unnest(c("projectTitle", "genusSpecies", "project_index"))

    tbl
}

.content_tibble(content)
```

Here's a more compact version where a vector of `elts` is used to
iterate on `.content_elt()`. The `lapply()` includes a named argument
`content = content`; the calls in the `lapply()` have the form
`.content_elt("projectTitle", content = content)`, and _R_'s rules for
argument matching mean that the iteration ends up being assigned ot
the `element=` argument, as desired.

```{r}
#' @importFrom tibble as_tibble
#'
#' @importFrom dplyr %>% mutate
#'
#' @importFrom tidyr unnest
#'
#' @importFrom tidyselect all_of
.content_tibble <-
    function(content)
{
    ## use a loop (`lapply()`) to extract each element of interest
    elts <- c("projectTitle", "genusSpecies")
    value <- lapply(elts, .content_elt, content = content)
    ## adding names here creates column names in the tibble
    names(value) <- elts

    tbl <-
        ## coerce named list to tibble
        as_tibble(value) %>%
        ## add hit and project indexes
        mutate(
            hit_index = seq_along(projectTitle),
            project_index = lapply(lengths(projectTitle), seq_len)
        ) %>%
        ## unnest all list columns; `all_of()` tells the tidyverse to
        ## look for `elts` in the calling environment, rather than as
        ## a column of the incoming tibble.
        unnest(all_of(c(elts, "project_index")))

    tbl
}

.content_tibble(content)
```
